{"ast":null,"code":"var _jsxFileName = \"/home/the00b/Escritorio/RAG_Gradio/client/src/contexts/PdfContext.js\",\n  _s = $RefreshSig$(),\n  _s2 = $RefreshSig$();\nimport React, { createContext, useState, useContext, useEffect } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst PdfContext = /*#__PURE__*/createContext();\nexport const usePdf = () => {\n  _s();\n  return useContext(PdfContext);\n};\n_s(usePdf, \"gDsCjeeItUuvgOWf1v4qoK9RF6k=\");\nexport const PdfContextProvider = ({\n  children\n}) => {\n  _s2();\n  const [pdfs, setPdfs] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const [selectedPdfs, setSelectedPdfs] = useState([]);\n  const [searchQuery, setSearchQuery] = useState('');\n  const [searchResults, setSearchResults] = useState(null);\n  const [summary, setSummary] = useState(null);\n  const [summaryLoading, setSummaryLoading] = useState(false);\n  const [queryLoading, setQueryLoading] = useState(false);\n  const [inputTokens, setInputTokens] = useState(0); // Contador de tokens de entrada\n  const [outputTokens, setOutputTokens] = useState(0); // Contador de tokens de salida\n  const [totalCostUSD, setTotalCostUSD] = useState(0); // Costo total en USD\n  const [currentModel, setCurrentModel] = useState('gpt-4o-mini'); // Modelo actual por defecto\n  const [pdfsProcessed, setPdfsProcessed] = useState(0); // Contador de PDFs procesados\n\n  // Load PDFs when component mounts\n  useEffect(() => {\n    fetchPdfs();\n  }, []);\n\n  // Fetch all PDFs from the server\n  const fetchPdfs = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.get('/api/pdf/list');\n      setPdfs(response.data.data || []);\n    } catch (err) {\n      var _err$response, _err$response$data;\n      setError('Error loading PDFs: ' + (((_err$response = err.response) === null || _err$response === void 0 ? void 0 : (_err$response$data = _err$response.data) === null || _err$response$data === void 0 ? void 0 : _err$response$data.message) || err.message));\n      console.error('Error fetching PDFs:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Upload a PDF\n  const uploadPdf = async file => {\n    try {\n      setLoading(true);\n      setError(null);\n      const formData = new FormData();\n      formData.append('file', file);\n      const response = await axios.post('/api/pdf/upload', formData, {\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      });\n\n      // Add the new PDF to the list\n      setPdfs(prev => [...prev, response.data.data]);\n      return response.data.data;\n    } catch (err) {\n      var _err$response2, _err$response2$data;\n      setError('Error uploading PDF: ' + (((_err$response2 = err.response) === null || _err$response2 === void 0 ? void 0 : (_err$response2$data = _err$response2.data) === null || _err$response2$data === void 0 ? void 0 : _err$response2$data.message) || err.message));\n      console.error('Error uploading PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Delete a PDF\n  const deletePdf = async id => {\n    try {\n      setLoading(true);\n      setError(null);\n      await axios.delete(`/api/pdf/delete/${id}`);\n\n      // Remove the PDF from the list\n      setPdfs(prev => prev.filter(pdf => pdf.id !== id));\n\n      // Remove from selected PDFs if it was selected\n      setSelectedPdfs(prev => prev.filter(pdfId => pdfId !== id));\n    } catch (err) {\n      var _err$response3, _err$response3$data;\n      setError('Error deleting PDF: ' + (((_err$response3 = err.response) === null || _err$response3 === void 0 ? void 0 : (_err$response3$data = _err$response3.data) === null || _err$response3$data === void 0 ? void 0 : _err$response3$data.message) || err.message));\n      console.error('Error deleting PDF:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Toggle PDF selection\n  const togglePdfSelection = id => {\n    setSelectedPdfs(prev => {\n      if (prev.includes(id)) {\n        return prev.filter(pdfId => pdfId !== id);\n      } else {\n        return [...prev, id];\n      }\n    });\n  };\n\n  // Process a query using OpenAI\n  // Función para calcular el costo basado en los tokens usados y el modelo\n  const calculateCost = (model, inputTokens, outputTokens) => {\n    // Precios en USD por millón de tokens\n    const prices = {\n      'gpt-4o': {\n        input: 2.50 / 1000000,\n        // $2.50 por millón de tokens de entrada\n        cachedInput: 1.25 / 1000000,\n        // $1.25 por millón de tokens de entrada en caché\n        output: 10.00 / 1000000 // $10.00 por millón de tokens de salida\n      },\n      'gpt-4o-mini': {\n        input: 0.15 / 1000000,\n        // $0.15 por millón de tokens de entrada\n        cachedInput: 0.075 / 1000000,\n        // $0.075 por millón de tokens de entrada en caché\n        output: 0.60 / 1000000 // $0.60 por millón de tokens de salida\n      },\n      'claude-3-sonnet-20240229': {\n        input: 3.00 / 1000000,\n        // $3.00 por millón de tokens de entrada\n        cachedInputWrite: 3.75 / 1000000,\n        // $3.75 por millón de tokens de entrada en caché (escritura)\n        cachedInputRead: 0.30 / 1000000,\n        // $0.30 por millón de tokens de entrada en caché (lectura)\n        cachedInput: 0.30 / 1000000,\n        // $0.30 por millón de tokens en caché (usamos el precio de lectura por defecto)\n        output: 15.00 / 1000000 // $15.00 por millón de tokens de salida\n      },\n      'deepseek-chat': {\n        input: 0.20 / 1000000,\n        // $0.20 por millón de tokens de entrada\n        cachedInput: 0.20 / 1000000,\n        // Mismo precio para caché\n        output: 0.80 / 1000000 // $0.80 por millón de tokens de salida\n      }\n    };\n\n    // Usar el modelo por defecto si el proporcionado no está en la lista\n    const modelPrices = prices[model] || prices['gpt-4o-mini'];\n\n    // Para el cálculo, usamos el precio estándar de entrada (no caché)\n    // En una implementación más avanzada, se podría determinar si fue caché de lectura o escritura\n    const inputCost = inputTokens * modelPrices.input;\n    const outputCost = outputTokens * modelPrices.output;\n    return inputCost + outputCost;\n  };\n  const processQuery = async (query, model = 'gpt-4o-mini', selectedPdfIds = [], maxTokens = 4000, temperature = 0.7, apiEndpoint = 'openai') => {\n    // Incrementar contador de PDFs procesados cuando hay PDFs seleccionados\n    const pdfIdsToUse = selectedPdfIds.length > 0 ? selectedPdfIds : selectedPdfs;\n    if (pdfIdsToUse.length > 0) {\n      setPdfsProcessed(prev => prev + pdfIdsToUse.length);\n    }\n\n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(model);\n\n    // Determinar el endpoint correcto basado en el modelo\n    const isClaudeModel = model.includes('claude');\n    const isDeepseekModel = model.includes('deepseek');\n    let actualEndpoint = 'openai';\n    if (isClaudeModel) {\n      actualEndpoint = 'anthropic';\n    } else if (isDeepseekModel) {\n      actualEndpoint = 'deepseek';\n    }\n    console.log(`Procesando consulta con modelo: ${model} a través del endpoint: /api/${actualEndpoint}/query`);\n    try {\n      setQueryLoading(true);\n      setError(null);\n      const payload = {\n        query,\n        fileIds: pdfIdsToUse.length > 0 ? pdfIdsToUse : undefined,\n        model: model,\n        max_tokens: maxTokens,\n        temperature: temperature\n      };\n      console.log('Enviando payload:', payload);\n      const response = await axios.post(`/api/${actualEndpoint}/query`, payload);\n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const {\n          promptTokens,\n          completionTokens,\n          totalTokens\n        } = responseData.tokenUsage;\n\n        // Convertir a números y asegurar que no son NaN\n        const newInputTokens = Number(promptTokens) || 0;\n        const newOutputTokens = Number(completionTokens) || 0;\n\n        // Actualizar los tokens de entrada y salida\n        setInputTokens(prev => prev + newInputTokens);\n        setOutputTokens(prev => prev + newOutputTokens);\n\n        // Calcular costo basado en el modelo actual\n        const cost = calculateCost(currentModel, newInputTokens, newOutputTokens);\n        setTotalCostUSD(prev => prev + cost);\n        console.log(`Tokens: ${newInputTokens} entrada, ${newOutputTokens} salida, ${totalTokens} total. Coste: $${cost.toFixed(6)}`);\n      }\n      setSearchResults(responseData);\n      return responseData;\n    } catch (err) {\n      console.error('Error procesando consulta:', err.response || err);\n\n      // Mensaje de error más informativo\n      let errorMessage = 'Error al procesar la consulta';\n      if (err.response) {\n        // El servidor respondió con un código de estado que cae fuera del rango de 2xx\n        errorMessage += `: ${err.response.status} ${err.response.statusText}`;\n        if (err.response.data && err.response.data.message) {\n          errorMessage += ` - ${err.response.data.message}`;\n        }\n      } else if (err.request) {\n        // La petición fue hecha pero no se recibió respuesta\n        errorMessage += ': No se recibió respuesta del servidor';\n      } else {\n        // Algo ocurrió al configurar la petición\n        errorMessage += `: ${err.message}`;\n      }\n      setError(errorMessage);\n      throw err;\n    } finally {\n      setQueryLoading(false);\n    }\n  };\n\n  // Generate a summary using OpenAI\n  const generateSummary = async (query, language = \"Español\", modelConfig = \"gpt-4o-mini\", modelParams = {\n    temperature: 0.7,\n    max_tokens: 4096,\n    top_p: 1,\n    frequency_penalty: 0,\n    presence_penalty: 0\n  }) => {\n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(modelConfig);\n\n    // Incrementar contador de PDFs procesados cuando hay PDFs seleccionados\n    if (selectedPdfs.length > 0) {\n      setPdfsProcessed(prev => prev + selectedPdfs.length);\n    }\n    try {\n      setSummaryLoading(true);\n      setError(null);\n\n      // Si modelParams es un string (para compatibilidad con versiones anteriores), convertirlo a objeto\n      const modelName = typeof modelParams === 'string' ? modelParams : modelParams.model;\n\n      // Determinar qué API utilizar\n      const isClaudeModel = modelName.includes('claude');\n      const isDeepseekModel = modelName.includes('deepseek');\n      let apiEndpoint = 'openai';\n      if (isClaudeModel) {\n        apiEndpoint = 'anthropic';\n      } else if (isDeepseekModel) {\n        apiEndpoint = 'deepseek';\n      }\n      const response = await axios.post(`/api/${apiEndpoint}/summary`, {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined,\n        language,\n        model: modelName,\n        // Añadir los parámetros avanzados separados del nombre del modelo\n        ...(typeof modelParams !== 'string' && {\n          temperature: modelParams.temperature,\n          max_tokens: modelParams.max_tokens,\n          top_p: modelParams.top_p,\n          frequency_penalty: modelParams.frequency_penalty,\n          presence_penalty: modelParams.presence_penalty\n        })\n      });\n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const {\n          promptTokens,\n          completionTokens,\n          totalTokens\n        } = responseData.tokenUsage;\n\n        // Convertir a números y asegurar que no son NaN\n        const newInputTokens = Number(promptTokens) || 0;\n        const newOutputTokens = Number(completionTokens) || 0;\n\n        // Actualizar los tokens de entrada y salida\n        setInputTokens(prev => prev + newInputTokens);\n        setOutputTokens(prev => prev + newOutputTokens);\n\n        // Calcular costo basado en el modelo actual\n        const cost = calculateCost(currentModel, newInputTokens, newOutputTokens);\n        setTotalCostUSD(prev => prev + cost);\n        console.log(`Tokens: ${newInputTokens} entrada, ${newOutputTokens} salida, ${totalTokens} total. Coste: $${cost.toFixed(6)}`);\n      }\n      setSummary(responseData);\n      return responseData;\n    } catch (err) {\n      var _err$response4, _err$response4$data;\n      setError('Error generating summary: ' + (((_err$response4 = err.response) === null || _err$response4 === void 0 ? void 0 : (_err$response4$data = _err$response4.data) === null || _err$response4$data === void 0 ? void 0 : _err$response4$data.message) || err.message));\n      console.error('Error generating summary:', err);\n      throw err;\n    } finally {\n      setSummaryLoading(false);\n    }\n  };\n\n  // Vectorize a PDF for better search\n  const vectorizePdf = async id => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.post('/api/openai/vectorize', {\n        fileId: id\n      });\n\n      // Update the PDF in the list\n      setPdfs(prev => prev.map(pdf => pdf.id === id ? {\n        ...pdf,\n        vectorized: true\n      } : pdf));\n      return response.data.data;\n    } catch (err) {\n      var _err$response5, _err$response5$data;\n      setError('Error vectorizing PDF: ' + (((_err$response5 = err.response) === null || _err$response5 === void 0 ? void 0 : (_err$response5$data = _err$response5.data) === null || _err$response5$data === void 0 ? void 0 : _err$response5$data.message) || err.message));\n      console.error('Error vectorizing PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Clear search results\n  const clearSearchResults = () => {\n    setSearchResults(null);\n  };\n\n  // Clear summary\n  const clearSummary = () => {\n    setSummary(null);\n  };\n  return /*#__PURE__*/_jsxDEV(PdfContext.Provider, {\n    value: {\n      pdfs,\n      loading,\n      error,\n      selectedPdfs,\n      searchQuery,\n      searchResults,\n      summary,\n      summaryLoading,\n      queryLoading,\n      totalTokensUsed: inputTokens + outputTokens,\n      // Calculado dinámicamente\n      inputTokens,\n      outputTokens,\n      totalCostUSD,\n      currentModel,\n      pdfsProcessed,\n      fetchPdfs,\n      uploadPdf,\n      deletePdf,\n      togglePdfSelection,\n      setSearchQuery,\n      processQuery,\n      generateSummary,\n      vectorizePdf,\n      clearSearchResults,\n      clearSummary,\n      setError\n    },\n    children: children\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 341,\n    columnNumber: 5\n  }, this);\n};\n_s2(PdfContextProvider, \"amDKWGQTaPWDr+q00X0Xu/NYZlA=\");\n_c = PdfContextProvider;\nvar _c;\n$RefreshReg$(_c, \"PdfContextProvider\");","map":{"version":3,"names":["React","createContext","useState","useContext","useEffect","axios","jsxDEV","_jsxDEV","PdfContext","usePdf","_s","PdfContextProvider","children","_s2","pdfs","setPdfs","loading","setLoading","error","setError","selectedPdfs","setSelectedPdfs","searchQuery","setSearchQuery","searchResults","setSearchResults","summary","setSummary","summaryLoading","setSummaryLoading","queryLoading","setQueryLoading","inputTokens","setInputTokens","outputTokens","setOutputTokens","totalCostUSD","setTotalCostUSD","currentModel","setCurrentModel","pdfsProcessed","setPdfsProcessed","fetchPdfs","response","get","data","err","_err$response","_err$response$data","message","console","uploadPdf","file","formData","FormData","append","post","headers","prev","_err$response2","_err$response2$data","deletePdf","id","delete","filter","pdf","pdfId","_err$response3","_err$response3$data","togglePdfSelection","includes","calculateCost","model","prices","input","cachedInput","output","cachedInputWrite","cachedInputRead","modelPrices","inputCost","outputCost","processQuery","query","selectedPdfIds","maxTokens","temperature","apiEndpoint","pdfIdsToUse","length","isClaudeModel","isDeepseekModel","actualEndpoint","log","payload","fileIds","undefined","max_tokens","responseData","tokenUsage","promptTokens","completionTokens","totalTokens","newInputTokens","Number","newOutputTokens","cost","toFixed","errorMessage","status","statusText","request","generateSummary","language","modelConfig","modelParams","top_p","frequency_penalty","presence_penalty","modelName","_err$response4","_err$response4$data","vectorizePdf","fileId","map","vectorized","_err$response5","_err$response5$data","clearSearchResults","clearSummary","Provider","value","totalTokensUsed","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/home/the00b/Escritorio/RAG_Gradio/client/src/contexts/PdfContext.js"],"sourcesContent":["import React, { createContext, useState, useContext, useEffect } from 'react';\nimport axios from 'axios';\n\nconst PdfContext = createContext();\n\nexport const usePdf = () => useContext(PdfContext);\n\nexport const PdfContextProvider = ({ children }) => {\n  const [pdfs, setPdfs] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const [selectedPdfs, setSelectedPdfs] = useState([]);\n  const [searchQuery, setSearchQuery] = useState('');\n  const [searchResults, setSearchResults] = useState(null);\n  const [summary, setSummary] = useState(null);\n  const [summaryLoading, setSummaryLoading] = useState(false);\n  const [queryLoading, setQueryLoading] = useState(false);\n  const [inputTokens, setInputTokens] = useState(0); // Contador de tokens de entrada\n  const [outputTokens, setOutputTokens] = useState(0); // Contador de tokens de salida\n  const [totalCostUSD, setTotalCostUSD] = useState(0); // Costo total en USD\n  const [currentModel, setCurrentModel] = useState('gpt-4o-mini'); // Modelo actual por defecto\n  const [pdfsProcessed, setPdfsProcessed] = useState(0); // Contador de PDFs procesados\n\n  // Load PDFs when component mounts\n  useEffect(() => {\n    fetchPdfs();\n  }, []);\n\n  // Fetch all PDFs from the server\n  const fetchPdfs = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.get('/api/pdf/list');\n      setPdfs(response.data.data || []);\n    } catch (err) {\n      setError('Error loading PDFs: ' + (err.response?.data?.message || err.message));\n      console.error('Error fetching PDFs:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Upload a PDF\n  const uploadPdf = async (file) => {\n    try {\n      setLoading(true);\n      setError(null);\n      \n      const formData = new FormData();\n      formData.append('file', file);\n      \n      const response = await axios.post('/api/pdf/upload', formData, {\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      });\n      \n      // Add the new PDF to the list\n      setPdfs(prev => [...prev, response.data.data]);\n      return response.data.data;\n    } catch (err) {\n      setError('Error uploading PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error uploading PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Delete a PDF\n  const deletePdf = async (id) => {\n    try {\n      setLoading(true);\n      setError(null);\n      await axios.delete(`/api/pdf/delete/${id}`);\n      \n      // Remove the PDF from the list\n      setPdfs(prev => prev.filter(pdf => pdf.id !== id));\n      \n      // Remove from selected PDFs if it was selected\n      setSelectedPdfs(prev => prev.filter(pdfId => pdfId !== id));\n    } catch (err) {\n      setError('Error deleting PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error deleting PDF:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Toggle PDF selection\n  const togglePdfSelection = (id) => {\n    setSelectedPdfs(prev => {\n      if (prev.includes(id)) {\n        return prev.filter(pdfId => pdfId !== id);\n      } else {\n        return [...prev, id];\n      }\n    });\n  };\n\n  // Process a query using OpenAI\n  // Función para calcular el costo basado en los tokens usados y el modelo\n  const calculateCost = (model, inputTokens, outputTokens) => {\n    // Precios en USD por millón de tokens\n    const prices = {\n      'gpt-4o': {\n        input: 2.50 / 1000000,      // $2.50 por millón de tokens de entrada\n        cachedInput: 1.25 / 1000000, // $1.25 por millón de tokens de entrada en caché\n        output: 10.00 / 1000000     // $10.00 por millón de tokens de salida\n      },\n      'gpt-4o-mini': {\n        input: 0.15 / 1000000,      // $0.15 por millón de tokens de entrada\n        cachedInput: 0.075 / 1000000, // $0.075 por millón de tokens de entrada en caché\n        output: 0.60 / 1000000      // $0.60 por millón de tokens de salida\n      },\n      'claude-3-sonnet-20240229': {\n        input: 3.00 / 1000000,        // $3.00 por millón de tokens de entrada\n        cachedInputWrite: 3.75 / 1000000, // $3.75 por millón de tokens de entrada en caché (escritura)\n        cachedInputRead: 0.30 / 1000000,  // $0.30 por millón de tokens de entrada en caché (lectura)\n        cachedInput: 0.30 / 1000000,   // $0.30 por millón de tokens en caché (usamos el precio de lectura por defecto)\n        output: 15.00 / 1000000       // $15.00 por millón de tokens de salida\n      },\n      'deepseek-chat': {\n        input: 0.20 / 1000000,       // $0.20 por millón de tokens de entrada\n        cachedInput: 0.20 / 1000000,  // Mismo precio para caché\n        output: 0.80 / 1000000       // $0.80 por millón de tokens de salida\n      }\n    };\n\n    // Usar el modelo por defecto si el proporcionado no está en la lista\n    const modelPrices = prices[model] || prices['gpt-4o-mini'];\n    \n    // Para el cálculo, usamos el precio estándar de entrada (no caché)\n    // En una implementación más avanzada, se podría determinar si fue caché de lectura o escritura\n    const inputCost = inputTokens * modelPrices.input;\n    const outputCost = outputTokens * modelPrices.output;\n    \n    return inputCost + outputCost;\n  };\n\n  const processQuery = async (query, model = 'gpt-4o-mini', selectedPdfIds = [], maxTokens = 4000, temperature = 0.7, apiEndpoint = 'openai') => {\n    // Incrementar contador de PDFs procesados cuando hay PDFs seleccionados\n    const pdfIdsToUse = selectedPdfIds.length > 0 ? selectedPdfIds : selectedPdfs;\n    if (pdfIdsToUse.length > 0) {\n      setPdfsProcessed(prev => prev + pdfIdsToUse.length);\n    }\n    \n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(model);\n    \n    // Determinar el endpoint correcto basado en el modelo\n    const isClaudeModel = model.includes('claude');\n    const isDeepseekModel = model.includes('deepseek');\n    \n    let actualEndpoint = 'openai';\n    if (isClaudeModel) {\n      actualEndpoint = 'anthropic';\n    } else if (isDeepseekModel) {\n      actualEndpoint = 'deepseek';\n    }\n    \n    console.log(`Procesando consulta con modelo: ${model} a través del endpoint: /api/${actualEndpoint}/query`);\n    \n    try {\n      setQueryLoading(true);\n      setError(null);\n      \n      const payload = {\n        query,\n        fileIds: pdfIdsToUse.length > 0 ? pdfIdsToUse : undefined,\n        model: model,\n        max_tokens: maxTokens,\n        temperature: temperature\n      };\n      \n      console.log('Enviando payload:', payload);\n      \n      const response = await axios.post(`/api/${actualEndpoint}/query`, payload);\n      \n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const { promptTokens, completionTokens, totalTokens } = responseData.tokenUsage;\n        \n        // Convertir a números y asegurar que no son NaN\n        const newInputTokens = Number(promptTokens) || 0;\n        const newOutputTokens = Number(completionTokens) || 0;\n        \n        // Actualizar los tokens de entrada y salida\n        setInputTokens(prev => prev + newInputTokens);\n        setOutputTokens(prev => prev + newOutputTokens);\n        \n        // Calcular costo basado en el modelo actual\n        const cost = calculateCost(currentModel, newInputTokens, newOutputTokens);\n        setTotalCostUSD(prev => prev + cost);\n        \n        console.log(`Tokens: ${newInputTokens} entrada, ${newOutputTokens} salida, ${totalTokens} total. Coste: $${cost.toFixed(6)}`);\n      }\n      \n      setSearchResults(responseData);\n      return responseData;\n    } catch (err) {\n      console.error('Error procesando consulta:', err.response || err);\n      \n      // Mensaje de error más informativo\n      let errorMessage = 'Error al procesar la consulta';\n      \n      if (err.response) {\n        // El servidor respondió con un código de estado que cae fuera del rango de 2xx\n        errorMessage += `: ${err.response.status} ${err.response.statusText}`;\n        if (err.response.data && err.response.data.message) {\n          errorMessage += ` - ${err.response.data.message}`;\n        }\n      } else if (err.request) {\n        // La petición fue hecha pero no se recibió respuesta\n        errorMessage += ': No se recibió respuesta del servidor';\n      } else {\n        // Algo ocurrió al configurar la petición\n        errorMessage += `: ${err.message}`;\n      }\n      \n      setError(errorMessage);\n      throw err;\n    } finally {\n      setQueryLoading(false);\n    }\n  };\n\n  // Generate a summary using OpenAI\n  const generateSummary = async (query, language = \"Español\", modelConfig = \"gpt-4o-mini\", modelParams = { temperature: 0.7, max_tokens: 4096, top_p: 1, frequency_penalty: 0, presence_penalty: 0 }) => {\n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(modelConfig);\n    \n    // Incrementar contador de PDFs procesados cuando hay PDFs seleccionados\n    if (selectedPdfs.length > 0) {\n      setPdfsProcessed(prev => prev + selectedPdfs.length);\n    }\n    try {\n      setSummaryLoading(true);\n      setError(null);\n      \n      // Si modelParams es un string (para compatibilidad con versiones anteriores), convertirlo a objeto\n      const modelName = typeof modelParams === 'string' \n        ? modelParams \n        : modelParams.model;\n      \n      // Determinar qué API utilizar\n      const isClaudeModel = modelName.includes('claude');\n      const isDeepseekModel = modelName.includes('deepseek');\n      \n      let apiEndpoint = 'openai';\n      if (isClaudeModel) {\n        apiEndpoint = 'anthropic';\n      } else if (isDeepseekModel) {\n        apiEndpoint = 'deepseek';\n      }\n        \n      const response = await axios.post(`/api/${apiEndpoint}/summary`, {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined,\n        language,\n        model: modelName,\n        // Añadir los parámetros avanzados separados del nombre del modelo\n        ...(typeof modelParams !== 'string' && {\n          temperature: modelParams.temperature,\n          max_tokens: modelParams.max_tokens,\n          top_p: modelParams.top_p,\n          frequency_penalty: modelParams.frequency_penalty,\n          presence_penalty: modelParams.presence_penalty\n        })\n      });\n      \n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const { promptTokens, completionTokens, totalTokens } = responseData.tokenUsage;\n        \n        // Convertir a números y asegurar que no son NaN\n        const newInputTokens = Number(promptTokens) || 0;\n        const newOutputTokens = Number(completionTokens) || 0;\n        \n        // Actualizar los tokens de entrada y salida\n        setInputTokens(prev => prev + newInputTokens);\n        setOutputTokens(prev => prev + newOutputTokens);\n        \n        // Calcular costo basado en el modelo actual\n        const cost = calculateCost(currentModel, newInputTokens, newOutputTokens);\n        setTotalCostUSD(prev => prev + cost);\n        \n        console.log(`Tokens: ${newInputTokens} entrada, ${newOutputTokens} salida, ${totalTokens} total. Coste: $${cost.toFixed(6)}`);\n      }\n      \n      setSummary(responseData);\n      return responseData;\n    } catch (err) {\n      setError('Error generating summary: ' + (err.response?.data?.message || err.message));\n      console.error('Error generating summary:', err);\n      throw err;\n    } finally {\n      setSummaryLoading(false);\n    }\n  };\n\n  // Vectorize a PDF for better search\n  const vectorizePdf = async (id) => {\n    try {\n      setLoading(true);\n      setError(null);\n      \n      const response = await axios.post('/api/openai/vectorize', {\n        fileId: id\n      });\n      \n      // Update the PDF in the list\n      setPdfs(prev => prev.map(pdf => \n        pdf.id === id ? { ...pdf, vectorized: true } : pdf\n      ));\n      \n      return response.data.data;\n    } catch (err) {\n      setError('Error vectorizing PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error vectorizing PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Clear search results\n  const clearSearchResults = () => {\n    setSearchResults(null);\n  };\n\n  // Clear summary\n  const clearSummary = () => {\n    setSummary(null);\n  };\n\n  return (\n    <PdfContext.Provider value={{\n      pdfs,\n      loading,\n      error,\n      selectedPdfs,\n      searchQuery,\n      searchResults,\n      summary,\n      summaryLoading,\n      queryLoading,\n      totalTokensUsed: inputTokens + outputTokens, // Calculado dinámicamente\n      inputTokens,\n      outputTokens,\n      totalCostUSD,\n      currentModel,\n      pdfsProcessed,\n      fetchPdfs,\n      uploadPdf,\n      deletePdf,\n      togglePdfSelection,\n      setSearchQuery,\n      processQuery,\n      generateSummary,\n      vectorizePdf,\n      clearSearchResults,\n      clearSummary,\n      setError\n    }}>\n      {children}\n    </PdfContext.Provider>\n  );\n};\n"],"mappings":";;;AAAA,OAAOA,KAAK,IAAIC,aAAa,EAAEC,QAAQ,EAAEC,UAAU,EAAEC,SAAS,QAAQ,OAAO;AAC7E,OAAOC,KAAK,MAAM,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,MAAMC,UAAU,gBAAGP,aAAa,CAAC,CAAC;AAElC,OAAO,MAAMQ,MAAM,GAAGA,CAAA;EAAAC,EAAA;EAAA,OAAMP,UAAU,CAACK,UAAU,CAAC;AAAA;AAACE,EAAA,CAAtCD,MAAM;AAEnB,OAAO,MAAME,kBAAkB,GAAGA,CAAC;EAAEC;AAAS,CAAC,KAAK;EAAAC,GAAA;EAClD,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGb,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACc,OAAO,EAAEC,UAAU,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EAC7C,MAAM,CAACgB,KAAK,EAAEC,QAAQ,CAAC,GAAGjB,QAAQ,CAAC,IAAI,CAAC;EACxC,MAAM,CAACkB,YAAY,EAAEC,eAAe,CAAC,GAAGnB,QAAQ,CAAC,EAAE,CAAC;EACpD,MAAM,CAACoB,WAAW,EAAEC,cAAc,CAAC,GAAGrB,QAAQ,CAAC,EAAE,CAAC;EAClD,MAAM,CAACsB,aAAa,EAAEC,gBAAgB,CAAC,GAAGvB,QAAQ,CAAC,IAAI,CAAC;EACxD,MAAM,CAACwB,OAAO,EAAEC,UAAU,CAAC,GAAGzB,QAAQ,CAAC,IAAI,CAAC;EAC5C,MAAM,CAAC0B,cAAc,EAAEC,iBAAiB,CAAC,GAAG3B,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAM,CAAC4B,YAAY,EAAEC,eAAe,CAAC,GAAG7B,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAAC8B,WAAW,EAAEC,cAAc,CAAC,GAAG/B,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACnD,MAAM,CAACgC,YAAY,EAAEC,eAAe,CAAC,GAAGjC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACrD,MAAM,CAACkC,YAAY,EAAEC,eAAe,CAAC,GAAGnC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACrD,MAAM,CAACoC,YAAY,EAAEC,eAAe,CAAC,GAAGrC,QAAQ,CAAC,aAAa,CAAC,CAAC,CAAC;EACjE,MAAM,CAACsC,aAAa,EAAEC,gBAAgB,CAAC,GAAGvC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;;EAEvD;EACAE,SAAS,CAAC,MAAM;IACdsC,SAAS,CAAC,CAAC;EACb,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMA,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACFzB,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MACd,MAAMwB,QAAQ,GAAG,MAAMtC,KAAK,CAACuC,GAAG,CAAC,eAAe,CAAC;MACjD7B,OAAO,CAAC4B,QAAQ,CAACE,IAAI,CAACA,IAAI,IAAI,EAAE,CAAC;IACnC,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAC,aAAA,EAAAC,kBAAA;MACZ7B,QAAQ,CAAC,sBAAsB,IAAI,EAAA4B,aAAA,GAAAD,GAAG,CAACH,QAAQ,cAAAI,aAAA,wBAAAC,kBAAA,GAAZD,aAAA,CAAcF,IAAI,cAAAG,kBAAA,uBAAlBA,kBAAA,CAAoBC,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAC/EC,OAAO,CAAChC,KAAK,CAAC,sBAAsB,EAAE4B,GAAG,CAAC;IAC5C,CAAC,SAAS;MACR7B,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAMkC,SAAS,GAAG,MAAOC,IAAI,IAAK;IAChC,IAAI;MACFnC,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAMkC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;MAC/BD,QAAQ,CAACE,MAAM,CAAC,MAAM,EAAEH,IAAI,CAAC;MAE7B,MAAMT,QAAQ,GAAG,MAAMtC,KAAK,CAACmD,IAAI,CAAC,iBAAiB,EAAEH,QAAQ,EAAE;QAC7DI,OAAO,EAAE;UACP,cAAc,EAAE;QAClB;MACF,CAAC,CAAC;;MAEF;MACA1C,OAAO,CAAC2C,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAEf,QAAQ,CAACE,IAAI,CAACA,IAAI,CAAC,CAAC;MAC9C,OAAOF,QAAQ,CAACE,IAAI,CAACA,IAAI;IAC3B,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAa,cAAA,EAAAC,mBAAA;MACZzC,QAAQ,CAAC,uBAAuB,IAAI,EAAAwC,cAAA,GAAAb,GAAG,CAACH,QAAQ,cAAAgB,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAcd,IAAI,cAAAe,mBAAA,uBAAlBA,mBAAA,CAAoBX,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAChFC,OAAO,CAAChC,KAAK,CAAC,sBAAsB,EAAE4B,GAAG,CAAC;MAC1C,MAAMA,GAAG;IACX,CAAC,SAAS;MACR7B,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAM4C,SAAS,GAAG,MAAOC,EAAE,IAAK;IAC9B,IAAI;MACF7C,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MACd,MAAMd,KAAK,CAAC0D,MAAM,CAAC,mBAAmBD,EAAE,EAAE,CAAC;;MAE3C;MACA/C,OAAO,CAAC2C,IAAI,IAAIA,IAAI,CAACM,MAAM,CAACC,GAAG,IAAIA,GAAG,CAACH,EAAE,KAAKA,EAAE,CAAC,CAAC;;MAElD;MACAzC,eAAe,CAACqC,IAAI,IAAIA,IAAI,CAACM,MAAM,CAACE,KAAK,IAAIA,KAAK,KAAKJ,EAAE,CAAC,CAAC;IAC7D,CAAC,CAAC,OAAOhB,GAAG,EAAE;MAAA,IAAAqB,cAAA,EAAAC,mBAAA;MACZjD,QAAQ,CAAC,sBAAsB,IAAI,EAAAgD,cAAA,GAAArB,GAAG,CAACH,QAAQ,cAAAwB,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAActB,IAAI,cAAAuB,mBAAA,uBAAlBA,mBAAA,CAAoBnB,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAC/EC,OAAO,CAAChC,KAAK,CAAC,qBAAqB,EAAE4B,GAAG,CAAC;IAC3C,CAAC,SAAS;MACR7B,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAMoD,kBAAkB,GAAIP,EAAE,IAAK;IACjCzC,eAAe,CAACqC,IAAI,IAAI;MACtB,IAAIA,IAAI,CAACY,QAAQ,CAACR,EAAE,CAAC,EAAE;QACrB,OAAOJ,IAAI,CAACM,MAAM,CAACE,KAAK,IAAIA,KAAK,KAAKJ,EAAE,CAAC;MAC3C,CAAC,MAAM;QACL,OAAO,CAAC,GAAGJ,IAAI,EAAEI,EAAE,CAAC;MACtB;IACF,CAAC,CAAC;EACJ,CAAC;;EAED;EACA;EACA,MAAMS,aAAa,GAAGA,CAACC,KAAK,EAAExC,WAAW,EAAEE,YAAY,KAAK;IAC1D;IACA,MAAMuC,MAAM,GAAG;MACb,QAAQ,EAAE;QACRC,KAAK,EAAE,IAAI,GAAG,OAAO;QAAO;QAC5BC,WAAW,EAAE,IAAI,GAAG,OAAO;QAAE;QAC7BC,MAAM,EAAE,KAAK,GAAG,OAAO,CAAK;MAC9B,CAAC;MACD,aAAa,EAAE;QACbF,KAAK,EAAE,IAAI,GAAG,OAAO;QAAO;QAC5BC,WAAW,EAAE,KAAK,GAAG,OAAO;QAAE;QAC9BC,MAAM,EAAE,IAAI,GAAG,OAAO,CAAM;MAC9B,CAAC;MACD,0BAA0B,EAAE;QAC1BF,KAAK,EAAE,IAAI,GAAG,OAAO;QAAS;QAC9BG,gBAAgB,EAAE,IAAI,GAAG,OAAO;QAAE;QAClCC,eAAe,EAAE,IAAI,GAAG,OAAO;QAAG;QAClCH,WAAW,EAAE,IAAI,GAAG,OAAO;QAAI;QAC/BC,MAAM,EAAE,KAAK,GAAG,OAAO,CAAO;MAChC,CAAC;MACD,eAAe,EAAE;QACfF,KAAK,EAAE,IAAI,GAAG,OAAO;QAAQ;QAC7BC,WAAW,EAAE,IAAI,GAAG,OAAO;QAAG;QAC9BC,MAAM,EAAE,IAAI,GAAG,OAAO,CAAO;MAC/B;IACF,CAAC;;IAED;IACA,MAAMG,WAAW,GAAGN,MAAM,CAACD,KAAK,CAAC,IAAIC,MAAM,CAAC,aAAa,CAAC;;IAE1D;IACA;IACA,MAAMO,SAAS,GAAGhD,WAAW,GAAG+C,WAAW,CAACL,KAAK;IACjD,MAAMO,UAAU,GAAG/C,YAAY,GAAG6C,WAAW,CAACH,MAAM;IAEpD,OAAOI,SAAS,GAAGC,UAAU;EAC/B,CAAC;EAED,MAAMC,YAAY,GAAG,MAAAA,CAAOC,KAAK,EAAEX,KAAK,GAAG,aAAa,EAAEY,cAAc,GAAG,EAAE,EAAEC,SAAS,GAAG,IAAI,EAAEC,WAAW,GAAG,GAAG,EAAEC,WAAW,GAAG,QAAQ,KAAK;IAC7I;IACA,MAAMC,WAAW,GAAGJ,cAAc,CAACK,MAAM,GAAG,CAAC,GAAGL,cAAc,GAAGhE,YAAY;IAC7E,IAAIoE,WAAW,CAACC,MAAM,GAAG,CAAC,EAAE;MAC1BhD,gBAAgB,CAACiB,IAAI,IAAIA,IAAI,GAAG8B,WAAW,CAACC,MAAM,CAAC;IACrD;;IAEA;IACAlD,eAAe,CAACiC,KAAK,CAAC;;IAEtB;IACA,MAAMkB,aAAa,GAAGlB,KAAK,CAACF,QAAQ,CAAC,QAAQ,CAAC;IAC9C,MAAMqB,eAAe,GAAGnB,KAAK,CAACF,QAAQ,CAAC,UAAU,CAAC;IAElD,IAAIsB,cAAc,GAAG,QAAQ;IAC7B,IAAIF,aAAa,EAAE;MACjBE,cAAc,GAAG,WAAW;IAC9B,CAAC,MAAM,IAAID,eAAe,EAAE;MAC1BC,cAAc,GAAG,UAAU;IAC7B;IAEA1C,OAAO,CAAC2C,GAAG,CAAC,mCAAmCrB,KAAK,gCAAgCoB,cAAc,QAAQ,CAAC;IAE3G,IAAI;MACF7D,eAAe,CAAC,IAAI,CAAC;MACrBZ,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAM2E,OAAO,GAAG;QACdX,KAAK;QACLY,OAAO,EAAEP,WAAW,CAACC,MAAM,GAAG,CAAC,GAAGD,WAAW,GAAGQ,SAAS;QACzDxB,KAAK,EAAEA,KAAK;QACZyB,UAAU,EAAEZ,SAAS;QACrBC,WAAW,EAAEA;MACf,CAAC;MAEDpC,OAAO,CAAC2C,GAAG,CAAC,mBAAmB,EAAEC,OAAO,CAAC;MAEzC,MAAMnD,QAAQ,GAAG,MAAMtC,KAAK,CAACmD,IAAI,CAAC,QAAQoC,cAAc,QAAQ,EAAEE,OAAO,CAAC;MAE1E,MAAMI,YAAY,GAAGvD,QAAQ,CAACE,IAAI,CAACA,IAAI;MACvC;MACA,IAAIqD,YAAY,CAACC,UAAU,EAAE;QAC3B,MAAM;UAAEC,YAAY;UAAEC,gBAAgB;UAAEC;QAAY,CAAC,GAAGJ,YAAY,CAACC,UAAU;;QAE/E;QACA,MAAMI,cAAc,GAAGC,MAAM,CAACJ,YAAY,CAAC,IAAI,CAAC;QAChD,MAAMK,eAAe,GAAGD,MAAM,CAACH,gBAAgB,CAAC,IAAI,CAAC;;QAErD;QACApE,cAAc,CAACyB,IAAI,IAAIA,IAAI,GAAG6C,cAAc,CAAC;QAC7CpE,eAAe,CAACuB,IAAI,IAAIA,IAAI,GAAG+C,eAAe,CAAC;;QAE/C;QACA,MAAMC,IAAI,GAAGnC,aAAa,CAACjC,YAAY,EAAEiE,cAAc,EAAEE,eAAe,CAAC;QACzEpE,eAAe,CAACqB,IAAI,IAAIA,IAAI,GAAGgD,IAAI,CAAC;QAEpCxD,OAAO,CAAC2C,GAAG,CAAC,WAAWU,cAAc,aAAaE,eAAe,YAAYH,WAAW,mBAAmBI,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;MAC/H;MAEAlF,gBAAgB,CAACyE,YAAY,CAAC;MAC9B,OAAOA,YAAY;IACrB,CAAC,CAAC,OAAOpD,GAAG,EAAE;MACZI,OAAO,CAAChC,KAAK,CAAC,4BAA4B,EAAE4B,GAAG,CAACH,QAAQ,IAAIG,GAAG,CAAC;;MAEhE;MACA,IAAI8D,YAAY,GAAG,+BAA+B;MAElD,IAAI9D,GAAG,CAACH,QAAQ,EAAE;QAChB;QACAiE,YAAY,IAAI,KAAK9D,GAAG,CAACH,QAAQ,CAACkE,MAAM,IAAI/D,GAAG,CAACH,QAAQ,CAACmE,UAAU,EAAE;QACrE,IAAIhE,GAAG,CAACH,QAAQ,CAACE,IAAI,IAAIC,GAAG,CAACH,QAAQ,CAACE,IAAI,CAACI,OAAO,EAAE;UAClD2D,YAAY,IAAI,MAAM9D,GAAG,CAACH,QAAQ,CAACE,IAAI,CAACI,OAAO,EAAE;QACnD;MACF,CAAC,MAAM,IAAIH,GAAG,CAACiE,OAAO,EAAE;QACtB;QACAH,YAAY,IAAI,wCAAwC;MAC1D,CAAC,MAAM;QACL;QACAA,YAAY,IAAI,KAAK9D,GAAG,CAACG,OAAO,EAAE;MACpC;MAEA9B,QAAQ,CAACyF,YAAY,CAAC;MACtB,MAAM9D,GAAG;IACX,CAAC,SAAS;MACRf,eAAe,CAAC,KAAK,CAAC;IACxB;EACF,CAAC;;EAED;EACA,MAAMiF,eAAe,GAAG,MAAAA,CAAO7B,KAAK,EAAE8B,QAAQ,GAAG,SAAS,EAAEC,WAAW,GAAG,aAAa,EAAEC,WAAW,GAAG;IAAE7B,WAAW,EAAE,GAAG;IAAEW,UAAU,EAAE,IAAI;IAAEmB,KAAK,EAAE,CAAC;IAAEC,iBAAiB,EAAE,CAAC;IAAEC,gBAAgB,EAAE;EAAE,CAAC,KAAK;IACrM;IACA/E,eAAe,CAAC2E,WAAW,CAAC;;IAE5B;IACA,IAAI9F,YAAY,CAACqE,MAAM,GAAG,CAAC,EAAE;MAC3BhD,gBAAgB,CAACiB,IAAI,IAAIA,IAAI,GAAGtC,YAAY,CAACqE,MAAM,CAAC;IACtD;IACA,IAAI;MACF5D,iBAAiB,CAAC,IAAI,CAAC;MACvBV,QAAQ,CAAC,IAAI,CAAC;;MAEd;MACA,MAAMoG,SAAS,GAAG,OAAOJ,WAAW,KAAK,QAAQ,GAC7CA,WAAW,GACXA,WAAW,CAAC3C,KAAK;;MAErB;MACA,MAAMkB,aAAa,GAAG6B,SAAS,CAACjD,QAAQ,CAAC,QAAQ,CAAC;MAClD,MAAMqB,eAAe,GAAG4B,SAAS,CAACjD,QAAQ,CAAC,UAAU,CAAC;MAEtD,IAAIiB,WAAW,GAAG,QAAQ;MAC1B,IAAIG,aAAa,EAAE;QACjBH,WAAW,GAAG,WAAW;MAC3B,CAAC,MAAM,IAAII,eAAe,EAAE;QAC1BJ,WAAW,GAAG,UAAU;MAC1B;MAEA,MAAM5C,QAAQ,GAAG,MAAMtC,KAAK,CAACmD,IAAI,CAAC,QAAQ+B,WAAW,UAAU,EAAE;QAC/DJ,KAAK;QACLY,OAAO,EAAE3E,YAAY,CAACqE,MAAM,GAAG,CAAC,GAAGrE,YAAY,GAAG4E,SAAS;QAC3DiB,QAAQ;QACRzC,KAAK,EAAE+C,SAAS;QAChB;QACA,IAAI,OAAOJ,WAAW,KAAK,QAAQ,IAAI;UACrC7B,WAAW,EAAE6B,WAAW,CAAC7B,WAAW;UACpCW,UAAU,EAAEkB,WAAW,CAAClB,UAAU;UAClCmB,KAAK,EAAED,WAAW,CAACC,KAAK;UACxBC,iBAAiB,EAAEF,WAAW,CAACE,iBAAiB;UAChDC,gBAAgB,EAAEH,WAAW,CAACG;QAChC,CAAC;MACH,CAAC,CAAC;MAEF,MAAMpB,YAAY,GAAGvD,QAAQ,CAACE,IAAI,CAACA,IAAI;MACvC;MACA,IAAIqD,YAAY,CAACC,UAAU,EAAE;QAC3B,MAAM;UAAEC,YAAY;UAAEC,gBAAgB;UAAEC;QAAY,CAAC,GAAGJ,YAAY,CAACC,UAAU;;QAE/E;QACA,MAAMI,cAAc,GAAGC,MAAM,CAACJ,YAAY,CAAC,IAAI,CAAC;QAChD,MAAMK,eAAe,GAAGD,MAAM,CAACH,gBAAgB,CAAC,IAAI,CAAC;;QAErD;QACApE,cAAc,CAACyB,IAAI,IAAIA,IAAI,GAAG6C,cAAc,CAAC;QAC7CpE,eAAe,CAACuB,IAAI,IAAIA,IAAI,GAAG+C,eAAe,CAAC;;QAE/C;QACA,MAAMC,IAAI,GAAGnC,aAAa,CAACjC,YAAY,EAAEiE,cAAc,EAAEE,eAAe,CAAC;QACzEpE,eAAe,CAACqB,IAAI,IAAIA,IAAI,GAAGgD,IAAI,CAAC;QAEpCxD,OAAO,CAAC2C,GAAG,CAAC,WAAWU,cAAc,aAAaE,eAAe,YAAYH,WAAW,mBAAmBI,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC;MAC/H;MAEAhF,UAAU,CAACuE,YAAY,CAAC;MACxB,OAAOA,YAAY;IACrB,CAAC,CAAC,OAAOpD,GAAG,EAAE;MAAA,IAAA0E,cAAA,EAAAC,mBAAA;MACZtG,QAAQ,CAAC,4BAA4B,IAAI,EAAAqG,cAAA,GAAA1E,GAAG,CAACH,QAAQ,cAAA6E,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAc3E,IAAI,cAAA4E,mBAAA,uBAAlBA,mBAAA,CAAoBxE,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MACrFC,OAAO,CAAChC,KAAK,CAAC,2BAA2B,EAAE4B,GAAG,CAAC;MAC/C,MAAMA,GAAG;IACX,CAAC,SAAS;MACRjB,iBAAiB,CAAC,KAAK,CAAC;IAC1B;EACF,CAAC;;EAED;EACA,MAAM6F,YAAY,GAAG,MAAO5D,EAAE,IAAK;IACjC,IAAI;MACF7C,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAMwB,QAAQ,GAAG,MAAMtC,KAAK,CAACmD,IAAI,CAAC,uBAAuB,EAAE;QACzDmE,MAAM,EAAE7D;MACV,CAAC,CAAC;;MAEF;MACA/C,OAAO,CAAC2C,IAAI,IAAIA,IAAI,CAACkE,GAAG,CAAC3D,GAAG,IAC1BA,GAAG,CAACH,EAAE,KAAKA,EAAE,GAAG;QAAE,GAAGG,GAAG;QAAE4D,UAAU,EAAE;MAAK,CAAC,GAAG5D,GACjD,CAAC,CAAC;MAEF,OAAOtB,QAAQ,CAACE,IAAI,CAACA,IAAI;IAC3B,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAgF,cAAA,EAAAC,mBAAA;MACZ5G,QAAQ,CAAC,yBAAyB,IAAI,EAAA2G,cAAA,GAAAhF,GAAG,CAACH,QAAQ,cAAAmF,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAcjF,IAAI,cAAAkF,mBAAA,uBAAlBA,mBAAA,CAAoB9E,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAClFC,OAAO,CAAChC,KAAK,CAAC,wBAAwB,EAAE4B,GAAG,CAAC;MAC5C,MAAMA,GAAG;IACX,CAAC,SAAS;MACR7B,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAM+G,kBAAkB,GAAGA,CAAA,KAAM;IAC/BvG,gBAAgB,CAAC,IAAI,CAAC;EACxB,CAAC;;EAED;EACA,MAAMwG,YAAY,GAAGA,CAAA,KAAM;IACzBtG,UAAU,CAAC,IAAI,CAAC;EAClB,CAAC;EAED,oBACEpB,OAAA,CAACC,UAAU,CAAC0H,QAAQ;IAACC,KAAK,EAAE;MAC1BrH,IAAI;MACJE,OAAO;MACPE,KAAK;MACLE,YAAY;MACZE,WAAW;MACXE,aAAa;MACbE,OAAO;MACPE,cAAc;MACdE,YAAY;MACZsG,eAAe,EAAEpG,WAAW,GAAGE,YAAY;MAAE;MAC7CF,WAAW;MACXE,YAAY;MACZE,YAAY;MACZE,YAAY;MACZE,aAAa;MACbE,SAAS;MACTS,SAAS;MACTU,SAAS;MACTQ,kBAAkB;MAClB9C,cAAc;MACd2D,YAAY;MACZ8B,eAAe;MACfU,YAAY;MACZM,kBAAkB;MAClBC,YAAY;MACZ9G;IACF,CAAE;IAAAP,QAAA,EACCA;EAAQ;IAAAyH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACU,CAAC;AAE1B,CAAC;AAAC3H,GAAA,CA5WWF,kBAAkB;AAAA8H,EAAA,GAAlB9H,kBAAkB;AAAA,IAAA8H,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}