{"ast":null,"code":"var _jsxFileName = \"/home/the00b/Escritorio/RAG_Gradio/client/src/contexts/PdfContext.js\",\n  _s = $RefreshSig$(),\n  _s2 = $RefreshSig$();\nimport React, { createContext, useState, useContext, useEffect } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst PdfContext = /*#__PURE__*/createContext();\nexport const usePdf = () => {\n  _s();\n  return useContext(PdfContext);\n};\n_s(usePdf, \"gDsCjeeItUuvgOWf1v4qoK9RF6k=\");\nexport const PdfContextProvider = ({\n  children\n}) => {\n  _s2();\n  const [pdfs, setPdfs] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const [selectedPdfs, setSelectedPdfs] = useState([]);\n  const [searchQuery, setSearchQuery] = useState('');\n  const [searchResults, setSearchResults] = useState(null);\n  const [summary, setSummary] = useState(null);\n  const [summaryLoading, setSummaryLoading] = useState(false);\n  const [queryLoading, setQueryLoading] = useState(false);\n  const [totalTokensUsed, setTotalTokensUsed] = useState(0); // Contador de tokens acumulados\n  const [totalCostUSD, setTotalCostUSD] = useState(0); // Costo total en USD\n  const [currentModel, setCurrentModel] = useState('gpt-4o-mini'); // Modelo actual por defecto\n\n  // Load PDFs when component mounts\n  useEffect(() => {\n    fetchPdfs();\n  }, []);\n\n  // Fetch all PDFs from the server\n  const fetchPdfs = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.get('/api/pdf/list');\n      setPdfs(response.data.data || []);\n    } catch (err) {\n      var _err$response, _err$response$data;\n      setError('Error loading PDFs: ' + (((_err$response = err.response) === null || _err$response === void 0 ? void 0 : (_err$response$data = _err$response.data) === null || _err$response$data === void 0 ? void 0 : _err$response$data.message) || err.message));\n      console.error('Error fetching PDFs:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Upload a PDF\n  const uploadPdf = async file => {\n    try {\n      setLoading(true);\n      setError(null);\n      const formData = new FormData();\n      formData.append('file', file);\n      const response = await axios.post('/api/pdf/upload', formData, {\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      });\n\n      // Add the new PDF to the list\n      setPdfs(prev => [...prev, response.data.data]);\n      return response.data.data;\n    } catch (err) {\n      var _err$response2, _err$response2$data;\n      setError('Error uploading PDF: ' + (((_err$response2 = err.response) === null || _err$response2 === void 0 ? void 0 : (_err$response2$data = _err$response2.data) === null || _err$response2$data === void 0 ? void 0 : _err$response2$data.message) || err.message));\n      console.error('Error uploading PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Delete a PDF\n  const deletePdf = async id => {\n    try {\n      setLoading(true);\n      setError(null);\n      await axios.delete(`/api/pdf/delete/${id}`);\n\n      // Remove the PDF from the list\n      setPdfs(prev => prev.filter(pdf => pdf.id !== id));\n\n      // Remove from selected PDFs if it was selected\n      setSelectedPdfs(prev => prev.filter(pdfId => pdfId !== id));\n    } catch (err) {\n      var _err$response3, _err$response3$data;\n      setError('Error deleting PDF: ' + (((_err$response3 = err.response) === null || _err$response3 === void 0 ? void 0 : (_err$response3$data = _err$response3.data) === null || _err$response3$data === void 0 ? void 0 : _err$response3$data.message) || err.message));\n      console.error('Error deleting PDF:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Toggle PDF selection\n  const togglePdfSelection = id => {\n    setSelectedPdfs(prev => {\n      if (prev.includes(id)) {\n        return prev.filter(pdfId => pdfId !== id);\n      } else {\n        return [...prev, id];\n      }\n    });\n  };\n\n  // Process a query using OpenAI\n  // Función para calcular el costo basado en los tokens usados y el modelo\n  const calculateCost = (model, inputTokens, outputTokens) => {\n    // Precios en USD por millón de tokens\n    const prices = {\n      'gpt-4o': {\n        input: 2.50 / 1000000,\n        // $2.50 por millón de tokens de entrada\n        cachedInput: 1.25 / 1000000,\n        // $1.25 por millón de tokens de entrada en caché\n        output: 10.00 / 1000000 // $10.00 por millón de tokens de salida\n      },\n      'gpt-4o-mini': {\n        input: 0.15 / 1000000,\n        // $0.15 por millón de tokens de entrada\n        cachedInput: 0.075 / 1000000,\n        // $0.075 por millón de tokens de entrada en caché\n        output: 0.60 / 1000000 // $0.60 por millón de tokens de salida\n      }\n    };\n\n    // Usar el modelo por defecto si el proporcionado no está en la lista\n    const modelPrices = prices[model] || prices['gpt-4o-mini'];\n\n    // No tenemos información sobre si es caché o no, asumimos input regular\n    const inputCost = inputTokens * modelPrices.input;\n    const outputCost = outputTokens * modelPrices.output;\n    return inputCost + outputCost;\n  };\n  const processQuery = async query => {\n    try {\n      setQueryLoading(true);\n      setError(null);\n      const response = await axios.post('/api/openai/query', {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined\n      });\n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const {\n          prompt: inputTokens,\n          completion: outputTokens,\n          total\n        } = responseData.tokenUsage;\n        setTotalTokensUsed(prevTotal => prevTotal + total);\n\n        // Calcular costo basado en el modelo y actualizar el total\n        const cost = calculateCost(currentModel, inputTokens, outputTokens);\n        setTotalCostUSD(prevCost => prevCost + cost);\n      }\n      setSearchResults(responseData);\n      return responseData;\n    } catch (err) {\n      var _err$response4, _err$response4$data;\n      setError('Error processing query: ' + (((_err$response4 = err.response) === null || _err$response4 === void 0 ? void 0 : (_err$response4$data = _err$response4.data) === null || _err$response4$data === void 0 ? void 0 : _err$response4$data.message) || err.message));\n      console.error('Error processing query:', err);\n      throw err;\n    } finally {\n      setQueryLoading(false);\n    }\n  };\n\n  // Generate a summary using OpenAI\n  const generateSummary = async (query, language = \"Español\", modelConfig = \"gpt-4o-mini\", modelParams = {\n    temperature: 0.7,\n    max_tokens: 4096,\n    top_p: 1,\n    frequency_penalty: 0,\n    presence_penalty: 0\n  }) => {\n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(modelConfig);\n    try {\n      setSummaryLoading(true);\n      setError(null);\n\n      // Si modelParams es un string (para compatibilidad con versiones anteriores), convertirlo a objeto\n      const modelConfig = typeof modelParams === 'string' ? modelParams : modelParams.model;\n      const response = await axios.post('/api/openai/summary', {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined,\n        language,\n        model: modelConfig,\n        // Añadir los parámetros avanzados separados del nombre del modelo\n        ...(typeof modelParams !== 'string' && {\n          temperature: modelParams.temperature,\n          max_tokens: modelParams.max_tokens,\n          top_p: modelParams.top_p,\n          frequency_penalty: modelParams.frequency_penalty,\n          presence_penalty: modelParams.presence_penalty\n        })\n      });\n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const {\n          prompt: inputTokens,\n          completion: outputTokens,\n          total\n        } = responseData.tokenUsage;\n        setTotalTokensUsed(prevTotal => prevTotal + total);\n\n        // Calcular costo basado en el modelo y actualizar el total\n        const cost = calculateCost(currentModel, inputTokens, outputTokens);\n        setTotalCostUSD(prevCost => prevCost + cost);\n      }\n      setSummary(responseData);\n      return responseData;\n    } catch (err) {\n      var _err$response5, _err$response5$data;\n      setError('Error generating summary: ' + (((_err$response5 = err.response) === null || _err$response5 === void 0 ? void 0 : (_err$response5$data = _err$response5.data) === null || _err$response5$data === void 0 ? void 0 : _err$response5$data.message) || err.message));\n      console.error('Error generating summary:', err);\n      throw err;\n    } finally {\n      setSummaryLoading(false);\n    }\n  };\n\n  // Vectorize a PDF for better search\n  const vectorizePdf = async id => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.post('/api/openai/vectorize', {\n        fileId: id\n      });\n\n      // Update the PDF in the list\n      setPdfs(prev => prev.map(pdf => pdf.id === id ? {\n        ...pdf,\n        vectorized: true\n      } : pdf));\n      return response.data.data;\n    } catch (err) {\n      var _err$response6, _err$response6$data;\n      setError('Error vectorizing PDF: ' + (((_err$response6 = err.response) === null || _err$response6 === void 0 ? void 0 : (_err$response6$data = _err$response6.data) === null || _err$response6$data === void 0 ? void 0 : _err$response6$data.message) || err.message));\n      console.error('Error vectorizing PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Clear search results\n  const clearSearchResults = () => {\n    setSearchResults(null);\n  };\n\n  // Clear summary\n  const clearSummary = () => {\n    setSummary(null);\n  };\n  return /*#__PURE__*/_jsxDEV(PdfContext.Provider, {\n    value: {\n      pdfs,\n      loading,\n      error,\n      selectedPdfs,\n      searchQuery,\n      searchResults,\n      summary,\n      summaryLoading,\n      queryLoading,\n      totalTokensUsed,\n      totalCostUSD,\n      currentModel,\n      fetchPdfs,\n      uploadPdf,\n      deletePdf,\n      togglePdfSelection,\n      setSearchQuery,\n      processQuery,\n      generateSummary,\n      vectorizePdf,\n      clearSearchResults,\n      clearSummary,\n      setError\n    },\n    children: children\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 245,\n    columnNumber: 5\n  }, this);\n};\n_s2(PdfContextProvider, \"eSRm56/+lY3A3ukKbmhBzBOpLf4=\");\n_c = PdfContextProvider;\nvar _c;\n$RefreshReg$(_c, \"PdfContextProvider\");","map":{"version":3,"names":["React","createContext","useState","useContext","useEffect","axios","jsxDEV","_jsxDEV","PdfContext","usePdf","_s","PdfContextProvider","children","_s2","pdfs","setPdfs","loading","setLoading","error","setError","selectedPdfs","setSelectedPdfs","searchQuery","setSearchQuery","searchResults","setSearchResults","summary","setSummary","summaryLoading","setSummaryLoading","queryLoading","setQueryLoading","totalTokensUsed","setTotalTokensUsed","totalCostUSD","setTotalCostUSD","currentModel","setCurrentModel","fetchPdfs","response","get","data","err","_err$response","_err$response$data","message","console","uploadPdf","file","formData","FormData","append","post","headers","prev","_err$response2","_err$response2$data","deletePdf","id","delete","filter","pdf","pdfId","_err$response3","_err$response3$data","togglePdfSelection","includes","calculateCost","model","inputTokens","outputTokens","prices","input","cachedInput","output","modelPrices","inputCost","outputCost","processQuery","query","fileIds","length","undefined","responseData","tokenUsage","prompt","completion","total","prevTotal","cost","prevCost","_err$response4","_err$response4$data","generateSummary","language","modelConfig","modelParams","temperature","max_tokens","top_p","frequency_penalty","presence_penalty","_err$response5","_err$response5$data","vectorizePdf","fileId","map","vectorized","_err$response6","_err$response6$data","clearSearchResults","clearSummary","Provider","value","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/home/the00b/Escritorio/RAG_Gradio/client/src/contexts/PdfContext.js"],"sourcesContent":["import React, { createContext, useState, useContext, useEffect } from 'react';\nimport axios from 'axios';\n\nconst PdfContext = createContext();\n\nexport const usePdf = () => useContext(PdfContext);\n\nexport const PdfContextProvider = ({ children }) => {\n  const [pdfs, setPdfs] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const [selectedPdfs, setSelectedPdfs] = useState([]);\n  const [searchQuery, setSearchQuery] = useState('');\n  const [searchResults, setSearchResults] = useState(null);\n  const [summary, setSummary] = useState(null);\n  const [summaryLoading, setSummaryLoading] = useState(false);\n  const [queryLoading, setQueryLoading] = useState(false);\n  const [totalTokensUsed, setTotalTokensUsed] = useState(0); // Contador de tokens acumulados\n  const [totalCostUSD, setTotalCostUSD] = useState(0); // Costo total en USD\n  const [currentModel, setCurrentModel] = useState('gpt-4o-mini'); // Modelo actual por defecto\n\n  // Load PDFs when component mounts\n  useEffect(() => {\n    fetchPdfs();\n  }, []);\n\n  // Fetch all PDFs from the server\n  const fetchPdfs = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n      const response = await axios.get('/api/pdf/list');\n      setPdfs(response.data.data || []);\n    } catch (err) {\n      setError('Error loading PDFs: ' + (err.response?.data?.message || err.message));\n      console.error('Error fetching PDFs:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Upload a PDF\n  const uploadPdf = async (file) => {\n    try {\n      setLoading(true);\n      setError(null);\n      \n      const formData = new FormData();\n      formData.append('file', file);\n      \n      const response = await axios.post('/api/pdf/upload', formData, {\n        headers: {\n          'Content-Type': 'multipart/form-data'\n        }\n      });\n      \n      // Add the new PDF to the list\n      setPdfs(prev => [...prev, response.data.data]);\n      return response.data.data;\n    } catch (err) {\n      setError('Error uploading PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error uploading PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Delete a PDF\n  const deletePdf = async (id) => {\n    try {\n      setLoading(true);\n      setError(null);\n      await axios.delete(`/api/pdf/delete/${id}`);\n      \n      // Remove the PDF from the list\n      setPdfs(prev => prev.filter(pdf => pdf.id !== id));\n      \n      // Remove from selected PDFs if it was selected\n      setSelectedPdfs(prev => prev.filter(pdfId => pdfId !== id));\n    } catch (err) {\n      setError('Error deleting PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error deleting PDF:', err);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Toggle PDF selection\n  const togglePdfSelection = (id) => {\n    setSelectedPdfs(prev => {\n      if (prev.includes(id)) {\n        return prev.filter(pdfId => pdfId !== id);\n      } else {\n        return [...prev, id];\n      }\n    });\n  };\n\n  // Process a query using OpenAI\n  // Función para calcular el costo basado en los tokens usados y el modelo\n  const calculateCost = (model, inputTokens, outputTokens) => {\n    // Precios en USD por millón de tokens\n    const prices = {\n      'gpt-4o': {\n        input: 2.50 / 1000000,      // $2.50 por millón de tokens de entrada\n        cachedInput: 1.25 / 1000000, // $1.25 por millón de tokens de entrada en caché\n        output: 10.00 / 1000000     // $10.00 por millón de tokens de salida\n      },\n      'gpt-4o-mini': {\n        input: 0.15 / 1000000,      // $0.15 por millón de tokens de entrada\n        cachedInput: 0.075 / 1000000, // $0.075 por millón de tokens de entrada en caché\n        output: 0.60 / 1000000      // $0.60 por millón de tokens de salida\n      }\n    };\n\n    // Usar el modelo por defecto si el proporcionado no está en la lista\n    const modelPrices = prices[model] || prices['gpt-4o-mini'];\n    \n    // No tenemos información sobre si es caché o no, asumimos input regular\n    const inputCost = inputTokens * modelPrices.input;\n    const outputCost = outputTokens * modelPrices.output;\n    \n    return inputCost + outputCost;\n  };\n\n  const processQuery = async (query) => {\n    try {\n      setQueryLoading(true);\n      setError(null);\n      \n      const response = await axios.post('/api/openai/query', {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined\n      });\n      \n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const { prompt: inputTokens, completion: outputTokens, total } = responseData.tokenUsage;\n        setTotalTokensUsed(prevTotal => prevTotal + total);\n        \n        // Calcular costo basado en el modelo y actualizar el total\n        const cost = calculateCost(currentModel, inputTokens, outputTokens);\n        setTotalCostUSD(prevCost => prevCost + cost);\n      }\n      \n      setSearchResults(responseData);\n      return responseData;\n    } catch (err) {\n      setError('Error processing query: ' + (err.response?.data?.message || err.message));\n      console.error('Error processing query:', err);\n      throw err;\n    } finally {\n      setQueryLoading(false);\n    }\n  };\n\n  // Generate a summary using OpenAI\n  const generateSummary = async (query, language = \"Español\", modelConfig = \"gpt-4o-mini\", modelParams = { temperature: 0.7, max_tokens: 4096, top_p: 1, frequency_penalty: 0, presence_penalty: 0 }) => {\n    // Actualizar el modelo actual para cálculos de coste\n    setCurrentModel(modelConfig);\n    try {\n      setSummaryLoading(true);\n      setError(null);\n      \n      // Si modelParams es un string (para compatibilidad con versiones anteriores), convertirlo a objeto\n      const modelConfig = typeof modelParams === 'string' \n        ? modelParams \n        : modelParams.model;\n        \n      const response = await axios.post('/api/openai/summary', {\n        query,\n        fileIds: selectedPdfs.length > 0 ? selectedPdfs : undefined,\n        language,\n        model: modelConfig,\n        // Añadir los parámetros avanzados separados del nombre del modelo\n        ...(typeof modelParams !== 'string' && {\n          temperature: modelParams.temperature,\n          max_tokens: modelParams.max_tokens,\n          top_p: modelParams.top_p,\n          frequency_penalty: modelParams.frequency_penalty,\n          presence_penalty: modelParams.presence_penalty\n        })\n      });\n      \n      const responseData = response.data.data;\n      // Actualizar contador de tokens si la respuesta incluye información de uso\n      if (responseData.tokenUsage) {\n        const { prompt: inputTokens, completion: outputTokens, total } = responseData.tokenUsage;\n        setTotalTokensUsed(prevTotal => prevTotal + total);\n        \n        // Calcular costo basado en el modelo y actualizar el total\n        const cost = calculateCost(currentModel, inputTokens, outputTokens);\n        setTotalCostUSD(prevCost => prevCost + cost);\n      }\n      \n      setSummary(responseData);\n      return responseData;\n    } catch (err) {\n      setError('Error generating summary: ' + (err.response?.data?.message || err.message));\n      console.error('Error generating summary:', err);\n      throw err;\n    } finally {\n      setSummaryLoading(false);\n    }\n  };\n\n  // Vectorize a PDF for better search\n  const vectorizePdf = async (id) => {\n    try {\n      setLoading(true);\n      setError(null);\n      \n      const response = await axios.post('/api/openai/vectorize', {\n        fileId: id\n      });\n      \n      // Update the PDF in the list\n      setPdfs(prev => prev.map(pdf => \n        pdf.id === id ? { ...pdf, vectorized: true } : pdf\n      ));\n      \n      return response.data.data;\n    } catch (err) {\n      setError('Error vectorizing PDF: ' + (err.response?.data?.message || err.message));\n      console.error('Error vectorizing PDF:', err);\n      throw err;\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Clear search results\n  const clearSearchResults = () => {\n    setSearchResults(null);\n  };\n\n  // Clear summary\n  const clearSummary = () => {\n    setSummary(null);\n  };\n\n  return (\n    <PdfContext.Provider value={{\n      pdfs,\n      loading,\n      error,\n      selectedPdfs,\n      searchQuery,\n      searchResults,\n      summary,\n      summaryLoading,\n      queryLoading,\n      totalTokensUsed,\n      totalCostUSD,\n      currentModel,\n      fetchPdfs,\n      uploadPdf,\n      deletePdf,\n      togglePdfSelection,\n      setSearchQuery,\n      processQuery,\n      generateSummary,\n      vectorizePdf,\n      clearSearchResults,\n      clearSummary,\n      setError\n    }}>\n      {children}\n    </PdfContext.Provider>\n  );\n};\n"],"mappings":";;;AAAA,OAAOA,KAAK,IAAIC,aAAa,EAAEC,QAAQ,EAAEC,UAAU,EAAEC,SAAS,QAAQ,OAAO;AAC7E,OAAOC,KAAK,MAAM,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1B,MAAMC,UAAU,gBAAGP,aAAa,CAAC,CAAC;AAElC,OAAO,MAAMQ,MAAM,GAAGA,CAAA;EAAAC,EAAA;EAAA,OAAMP,UAAU,CAACK,UAAU,CAAC;AAAA;AAACE,EAAA,CAAtCD,MAAM;AAEnB,OAAO,MAAME,kBAAkB,GAAGA,CAAC;EAAEC;AAAS,CAAC,KAAK;EAAAC,GAAA;EAClD,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGb,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACc,OAAO,EAAEC,UAAU,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EAC7C,MAAM,CAACgB,KAAK,EAAEC,QAAQ,CAAC,GAAGjB,QAAQ,CAAC,IAAI,CAAC;EACxC,MAAM,CAACkB,YAAY,EAAEC,eAAe,CAAC,GAAGnB,QAAQ,CAAC,EAAE,CAAC;EACpD,MAAM,CAACoB,WAAW,EAAEC,cAAc,CAAC,GAAGrB,QAAQ,CAAC,EAAE,CAAC;EAClD,MAAM,CAACsB,aAAa,EAAEC,gBAAgB,CAAC,GAAGvB,QAAQ,CAAC,IAAI,CAAC;EACxD,MAAM,CAACwB,OAAO,EAAEC,UAAU,CAAC,GAAGzB,QAAQ,CAAC,IAAI,CAAC;EAC5C,MAAM,CAAC0B,cAAc,EAAEC,iBAAiB,CAAC,GAAG3B,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAM,CAAC4B,YAAY,EAAEC,eAAe,CAAC,GAAG7B,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAAC8B,eAAe,EAAEC,kBAAkB,CAAC,GAAG/B,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EAC3D,MAAM,CAACgC,YAAY,EAAEC,eAAe,CAAC,GAAGjC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;EACrD,MAAM,CAACkC,YAAY,EAAEC,eAAe,CAAC,GAAGnC,QAAQ,CAAC,aAAa,CAAC,CAAC,CAAC;;EAEjE;EACAE,SAAS,CAAC,MAAM;IACdkC,SAAS,CAAC,CAAC;EACb,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMA,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACFrB,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MACd,MAAMoB,QAAQ,GAAG,MAAMlC,KAAK,CAACmC,GAAG,CAAC,eAAe,CAAC;MACjDzB,OAAO,CAACwB,QAAQ,CAACE,IAAI,CAACA,IAAI,IAAI,EAAE,CAAC;IACnC,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAC,aAAA,EAAAC,kBAAA;MACZzB,QAAQ,CAAC,sBAAsB,IAAI,EAAAwB,aAAA,GAAAD,GAAG,CAACH,QAAQ,cAAAI,aAAA,wBAAAC,kBAAA,GAAZD,aAAA,CAAcF,IAAI,cAAAG,kBAAA,uBAAlBA,kBAAA,CAAoBC,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAC/EC,OAAO,CAAC5B,KAAK,CAAC,sBAAsB,EAAEwB,GAAG,CAAC;IAC5C,CAAC,SAAS;MACRzB,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAM8B,SAAS,GAAG,MAAOC,IAAI,IAAK;IAChC,IAAI;MACF/B,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAM8B,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;MAC/BD,QAAQ,CAACE,MAAM,CAAC,MAAM,EAAEH,IAAI,CAAC;MAE7B,MAAMT,QAAQ,GAAG,MAAMlC,KAAK,CAAC+C,IAAI,CAAC,iBAAiB,EAAEH,QAAQ,EAAE;QAC7DI,OAAO,EAAE;UACP,cAAc,EAAE;QAClB;MACF,CAAC,CAAC;;MAEF;MACAtC,OAAO,CAACuC,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAEf,QAAQ,CAACE,IAAI,CAACA,IAAI,CAAC,CAAC;MAC9C,OAAOF,QAAQ,CAACE,IAAI,CAACA,IAAI;IAC3B,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAa,cAAA,EAAAC,mBAAA;MACZrC,QAAQ,CAAC,uBAAuB,IAAI,EAAAoC,cAAA,GAAAb,GAAG,CAACH,QAAQ,cAAAgB,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAcd,IAAI,cAAAe,mBAAA,uBAAlBA,mBAAA,CAAoBX,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAChFC,OAAO,CAAC5B,KAAK,CAAC,sBAAsB,EAAEwB,GAAG,CAAC;MAC1C,MAAMA,GAAG;IACX,CAAC,SAAS;MACRzB,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAMwC,SAAS,GAAG,MAAOC,EAAE,IAAK;IAC9B,IAAI;MACFzC,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MACd,MAAMd,KAAK,CAACsD,MAAM,CAAC,mBAAmBD,EAAE,EAAE,CAAC;;MAE3C;MACA3C,OAAO,CAACuC,IAAI,IAAIA,IAAI,CAACM,MAAM,CAACC,GAAG,IAAIA,GAAG,CAACH,EAAE,KAAKA,EAAE,CAAC,CAAC;;MAElD;MACArC,eAAe,CAACiC,IAAI,IAAIA,IAAI,CAACM,MAAM,CAACE,KAAK,IAAIA,KAAK,KAAKJ,EAAE,CAAC,CAAC;IAC7D,CAAC,CAAC,OAAOhB,GAAG,EAAE;MAAA,IAAAqB,cAAA,EAAAC,mBAAA;MACZ7C,QAAQ,CAAC,sBAAsB,IAAI,EAAA4C,cAAA,GAAArB,GAAG,CAACH,QAAQ,cAAAwB,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAActB,IAAI,cAAAuB,mBAAA,uBAAlBA,mBAAA,CAAoBnB,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAC/EC,OAAO,CAAC5B,KAAK,CAAC,qBAAqB,EAAEwB,GAAG,CAAC;IAC3C,CAAC,SAAS;MACRzB,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAMgD,kBAAkB,GAAIP,EAAE,IAAK;IACjCrC,eAAe,CAACiC,IAAI,IAAI;MACtB,IAAIA,IAAI,CAACY,QAAQ,CAACR,EAAE,CAAC,EAAE;QACrB,OAAOJ,IAAI,CAACM,MAAM,CAACE,KAAK,IAAIA,KAAK,KAAKJ,EAAE,CAAC;MAC3C,CAAC,MAAM;QACL,OAAO,CAAC,GAAGJ,IAAI,EAAEI,EAAE,CAAC;MACtB;IACF,CAAC,CAAC;EACJ,CAAC;;EAED;EACA;EACA,MAAMS,aAAa,GAAGA,CAACC,KAAK,EAAEC,WAAW,EAAEC,YAAY,KAAK;IAC1D;IACA,MAAMC,MAAM,GAAG;MACb,QAAQ,EAAE;QACRC,KAAK,EAAE,IAAI,GAAG,OAAO;QAAO;QAC5BC,WAAW,EAAE,IAAI,GAAG,OAAO;QAAE;QAC7BC,MAAM,EAAE,KAAK,GAAG,OAAO,CAAK;MAC9B,CAAC;MACD,aAAa,EAAE;QACbF,KAAK,EAAE,IAAI,GAAG,OAAO;QAAO;QAC5BC,WAAW,EAAE,KAAK,GAAG,OAAO;QAAE;QAC9BC,MAAM,EAAE,IAAI,GAAG,OAAO,CAAM;MAC9B;IACF,CAAC;;IAED;IACA,MAAMC,WAAW,GAAGJ,MAAM,CAACH,KAAK,CAAC,IAAIG,MAAM,CAAC,aAAa,CAAC;;IAE1D;IACA,MAAMK,SAAS,GAAGP,WAAW,GAAGM,WAAW,CAACH,KAAK;IACjD,MAAMK,UAAU,GAAGP,YAAY,GAAGK,WAAW,CAACD,MAAM;IAEpD,OAAOE,SAAS,GAAGC,UAAU;EAC/B,CAAC;EAED,MAAMC,YAAY,GAAG,MAAOC,KAAK,IAAK;IACpC,IAAI;MACFhD,eAAe,CAAC,IAAI,CAAC;MACrBZ,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAMoB,QAAQ,GAAG,MAAMlC,KAAK,CAAC+C,IAAI,CAAC,mBAAmB,EAAE;QACrD2B,KAAK;QACLC,OAAO,EAAE5D,YAAY,CAAC6D,MAAM,GAAG,CAAC,GAAG7D,YAAY,GAAG8D;MACpD,CAAC,CAAC;MAEF,MAAMC,YAAY,GAAG5C,QAAQ,CAACE,IAAI,CAACA,IAAI;MACvC;MACA,IAAI0C,YAAY,CAACC,UAAU,EAAE;QAC3B,MAAM;UAAEC,MAAM,EAAEhB,WAAW;UAAEiB,UAAU,EAAEhB,YAAY;UAAEiB;QAAM,CAAC,GAAGJ,YAAY,CAACC,UAAU;QACxFnD,kBAAkB,CAACuD,SAAS,IAAIA,SAAS,GAAGD,KAAK,CAAC;;QAElD;QACA,MAAME,IAAI,GAAGtB,aAAa,CAAC/B,YAAY,EAAEiC,WAAW,EAAEC,YAAY,CAAC;QACnEnC,eAAe,CAACuD,QAAQ,IAAIA,QAAQ,GAAGD,IAAI,CAAC;MAC9C;MAEAhE,gBAAgB,CAAC0D,YAAY,CAAC;MAC9B,OAAOA,YAAY;IACrB,CAAC,CAAC,OAAOzC,GAAG,EAAE;MAAA,IAAAiD,cAAA,EAAAC,mBAAA;MACZzE,QAAQ,CAAC,0BAA0B,IAAI,EAAAwE,cAAA,GAAAjD,GAAG,CAACH,QAAQ,cAAAoD,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAclD,IAAI,cAAAmD,mBAAA,uBAAlBA,mBAAA,CAAoB/C,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MACnFC,OAAO,CAAC5B,KAAK,CAAC,yBAAyB,EAAEwB,GAAG,CAAC;MAC7C,MAAMA,GAAG;IACX,CAAC,SAAS;MACRX,eAAe,CAAC,KAAK,CAAC;IACxB;EACF,CAAC;;EAED;EACA,MAAM8D,eAAe,GAAG,MAAAA,CAAOd,KAAK,EAAEe,QAAQ,GAAG,SAAS,EAAEC,WAAW,GAAG,aAAa,EAAEC,WAAW,GAAG;IAAEC,WAAW,EAAE,GAAG;IAAEC,UAAU,EAAE,IAAI;IAAEC,KAAK,EAAE,CAAC;IAAEC,iBAAiB,EAAE,CAAC;IAAEC,gBAAgB,EAAE;EAAE,CAAC,KAAK;IACrM;IACAhE,eAAe,CAAC0D,WAAW,CAAC;IAC5B,IAAI;MACFlE,iBAAiB,CAAC,IAAI,CAAC;MACvBV,QAAQ,CAAC,IAAI,CAAC;;MAEd;MACA,MAAM4E,WAAW,GAAG,OAAOC,WAAW,KAAK,QAAQ,GAC/CA,WAAW,GACXA,WAAW,CAAC5B,KAAK;MAErB,MAAM7B,QAAQ,GAAG,MAAMlC,KAAK,CAAC+C,IAAI,CAAC,qBAAqB,EAAE;QACvD2B,KAAK;QACLC,OAAO,EAAE5D,YAAY,CAAC6D,MAAM,GAAG,CAAC,GAAG7D,YAAY,GAAG8D,SAAS;QAC3DY,QAAQ;QACR1B,KAAK,EAAE2B,WAAW;QAClB;QACA,IAAI,OAAOC,WAAW,KAAK,QAAQ,IAAI;UACrCC,WAAW,EAAED,WAAW,CAACC,WAAW;UACpCC,UAAU,EAAEF,WAAW,CAACE,UAAU;UAClCC,KAAK,EAAEH,WAAW,CAACG,KAAK;UACxBC,iBAAiB,EAAEJ,WAAW,CAACI,iBAAiB;UAChDC,gBAAgB,EAAEL,WAAW,CAACK;QAChC,CAAC;MACH,CAAC,CAAC;MAEF,MAAMlB,YAAY,GAAG5C,QAAQ,CAACE,IAAI,CAACA,IAAI;MACvC;MACA,IAAI0C,YAAY,CAACC,UAAU,EAAE;QAC3B,MAAM;UAAEC,MAAM,EAAEhB,WAAW;UAAEiB,UAAU,EAAEhB,YAAY;UAAEiB;QAAM,CAAC,GAAGJ,YAAY,CAACC,UAAU;QACxFnD,kBAAkB,CAACuD,SAAS,IAAIA,SAAS,GAAGD,KAAK,CAAC;;QAElD;QACA,MAAME,IAAI,GAAGtB,aAAa,CAAC/B,YAAY,EAAEiC,WAAW,EAAEC,YAAY,CAAC;QACnEnC,eAAe,CAACuD,QAAQ,IAAIA,QAAQ,GAAGD,IAAI,CAAC;MAC9C;MAEA9D,UAAU,CAACwD,YAAY,CAAC;MACxB,OAAOA,YAAY;IACrB,CAAC,CAAC,OAAOzC,GAAG,EAAE;MAAA,IAAA4D,cAAA,EAAAC,mBAAA;MACZpF,QAAQ,CAAC,4BAA4B,IAAI,EAAAmF,cAAA,GAAA5D,GAAG,CAACH,QAAQ,cAAA+D,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAc7D,IAAI,cAAA8D,mBAAA,uBAAlBA,mBAAA,CAAoB1D,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MACrFC,OAAO,CAAC5B,KAAK,CAAC,2BAA2B,EAAEwB,GAAG,CAAC;MAC/C,MAAMA,GAAG;IACX,CAAC,SAAS;MACRb,iBAAiB,CAAC,KAAK,CAAC;IAC1B;EACF,CAAC;;EAED;EACA,MAAM2E,YAAY,GAAG,MAAO9C,EAAE,IAAK;IACjC,IAAI;MACFzC,UAAU,CAAC,IAAI,CAAC;MAChBE,QAAQ,CAAC,IAAI,CAAC;MAEd,MAAMoB,QAAQ,GAAG,MAAMlC,KAAK,CAAC+C,IAAI,CAAC,uBAAuB,EAAE;QACzDqD,MAAM,EAAE/C;MACV,CAAC,CAAC;;MAEF;MACA3C,OAAO,CAACuC,IAAI,IAAIA,IAAI,CAACoD,GAAG,CAAC7C,GAAG,IAC1BA,GAAG,CAACH,EAAE,KAAKA,EAAE,GAAG;QAAE,GAAGG,GAAG;QAAE8C,UAAU,EAAE;MAAK,CAAC,GAAG9C,GACjD,CAAC,CAAC;MAEF,OAAOtB,QAAQ,CAACE,IAAI,CAACA,IAAI;IAC3B,CAAC,CAAC,OAAOC,GAAG,EAAE;MAAA,IAAAkE,cAAA,EAAAC,mBAAA;MACZ1F,QAAQ,CAAC,yBAAyB,IAAI,EAAAyF,cAAA,GAAAlE,GAAG,CAACH,QAAQ,cAAAqE,cAAA,wBAAAC,mBAAA,GAAZD,cAAA,CAAcnE,IAAI,cAAAoE,mBAAA,uBAAlBA,mBAAA,CAAoBhE,OAAO,KAAIH,GAAG,CAACG,OAAO,CAAC,CAAC;MAClFC,OAAO,CAAC5B,KAAK,CAAC,wBAAwB,EAAEwB,GAAG,CAAC;MAC5C,MAAMA,GAAG;IACX,CAAC,SAAS;MACRzB,UAAU,CAAC,KAAK,CAAC;IACnB;EACF,CAAC;;EAED;EACA,MAAM6F,kBAAkB,GAAGA,CAAA,KAAM;IAC/BrF,gBAAgB,CAAC,IAAI,CAAC;EACxB,CAAC;;EAED;EACA,MAAMsF,YAAY,GAAGA,CAAA,KAAM;IACzBpF,UAAU,CAAC,IAAI,CAAC;EAClB,CAAC;EAED,oBACEpB,OAAA,CAACC,UAAU,CAACwG,QAAQ;IAACC,KAAK,EAAE;MAC1BnG,IAAI;MACJE,OAAO;MACPE,KAAK;MACLE,YAAY;MACZE,WAAW;MACXE,aAAa;MACbE,OAAO;MACPE,cAAc;MACdE,YAAY;MACZE,eAAe;MACfE,YAAY;MACZE,YAAY;MACZE,SAAS;MACTS,SAAS;MACTU,SAAS;MACTQ,kBAAkB;MAClB1C,cAAc;MACduD,YAAY;MACZe,eAAe;MACfW,YAAY;MACZM,kBAAkB;MAClBC,YAAY;MACZ5F;IACF,CAAE;IAAAP,QAAA,EACCA;EAAQ;IAAAsG,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACU,CAAC;AAE1B,CAAC;AAACxG,GAAA,CAzQWF,kBAAkB;AAAA2G,EAAA,GAAlB3G,kBAAkB;AAAA,IAAA2G,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}